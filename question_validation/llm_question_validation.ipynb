{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to update token costs. Using static costs.\n",
      "/Users/junaid/.virtualenvs/audenshaw_exam_validation/lib/python3.11/site-packages/tokencost/constants.py:61: RuntimeWarning: coroutine 'update_token_costs' was never awaited\n",
      "  TOKEN_COSTS = TOKEN_COSTS_STATIC\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from llm_assessor import (\n",
    "    ranged_error\n",
    ")\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/junaid/Developer/audenshaw_exam_validation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set working directory - Not required if using Jupyter outside of VScode\n",
    "workdir = os.environ[\"workdir\"]\n",
    "os.chdir(workdir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataframe\n",
    "data_dir = Path(\"./validation_results\")\n",
    "\n",
    "teacher_marked_questions = pd.read_csv(data_dir / \"processed_data\" / \"student_answers_llm_graded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>student_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>mark_scheme_text</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>awarded_marks</th>\n",
       "      <th>total_marks</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>answer_scanned_image</th>\n",
       "      <th>start_time</th>\n",
       "      <th>llm_graded_answer</th>\n",
       "      <th>llm_graded_answer_token_costing</th>\n",
       "      <th>llm_awarded_marks</th>\n",
       "      <th>llm_awarded_marks_token_costing</th>\n",
       "      <th>llm_mark_hitrate</th>\n",
       "      <th>end_time</th>\n",
       "      <th>elapsed_time_in_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aqa_history</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hs_explain</td>\n",
       "      <td>5000</td>\n",
       "      <td>Source A is critical of the Bolsheviks during ...</td>\n",
       "      <td>Level_2:\\n  description: \\n    - Developed ana...</td>\n",
       "      <td>Source A:  A British cartoon entitled ‘Betraye...</td>\n",
       "      <td>Source A is critical of the \\nBolsheviks as in...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>### Step-by-Step Grading Explanation\\n\\n#### 1...</td>\n",
       "      <td>{'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>2</td>\n",
       "      <td>{'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>39.719050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqa_history</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hs_explain</td>\n",
       "      <td>5000</td>\n",
       "      <td>How useful are Sources B and C to an historian...</td>\n",
       "      <td>Level_4:\\n  description: \\n    - Complex evalu...</td>\n",
       "      <td>Source B A picture published in a British news...</td>\n",
       "      <td>\\nI think Sources\\nB and C are very useful to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>### Step-by-Step Grading Explanation\\n\\n#### 1...</td>\n",
       "      <td>{'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>4</td>\n",
       "      <td>{'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>27.226788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aqa_history</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>5000</td>\n",
       "      <td>Write an account of how the Schlieffen Plan le...</td>\n",
       "      <td>Level_4:\\n  description: \\n    - Answer is pre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Schlieffen plan led to problems in 1914 as...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>### Step-by-Step Grading Explanation\\n\\n#### 1...</td>\n",
       "      <td>{'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>22.838951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aqa_history</td>\n",
       "      <td>4.1</td>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>5000</td>\n",
       "      <td>The Alliance System was the main cause of the ...</td>\n",
       "      <td>Level_4:\\n  description: \\n    - Complex expla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I agree with this statement as I believe the ...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>### Step-by-Step Grading Explanation\\n\\n#### 1...</td>\n",
       "      <td>{'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>36.361025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aqa_history</td>\n",
       "      <td>4.2</td>\n",
       "      <td>hs_spag</td>\n",
       "      <td>5000</td>\n",
       "      <td>The Alliance System was the main cause of the ...</td>\n",
       "      <td>Level_4:\\n  description: \\n    - High Performa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I agree with this statement as I believe the ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>Based on the provided Mark Scheme, let's asses...</td>\n",
       "      <td>{'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>3</td>\n",
       "      <td>{'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.721054e+09</td>\n",
       "      <td>20.125219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  question_id question_type  student_id  \\\n",
       "0  aqa_history          1.0    hs_explain        5000   \n",
       "1  aqa_history          2.0    hs_explain        5000   \n",
       "2  aqa_history          3.0    hs_analyse        5000   \n",
       "3  aqa_history          4.1  hs_judgement        5000   \n",
       "4  aqa_history          4.2       hs_spag        5000   \n",
       "\n",
       "                                       question_text  \\\n",
       "0  Source A is critical of the Bolsheviks during ...   \n",
       "1  How useful are Sources B and C to an historian...   \n",
       "2  Write an account of how the Schlieffen Plan le...   \n",
       "3  The Alliance System was the main cause of the ...   \n",
       "4  The Alliance System was the main cause of the ...   \n",
       "\n",
       "                                    mark_scheme_text  \\\n",
       "0  Level_2:\\n  description: \\n    - Developed ana...   \n",
       "1  Level_4:\\n  description: \\n    - Complex evalu...   \n",
       "2  Level_4:\\n  description: \\n    - Answer is pre...   \n",
       "3  Level_4:\\n  description: \\n    - Complex expla...   \n",
       "4  Level_4:\\n  description: \\n    - High Performa...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Source A:  A British cartoon entitled ‘Betraye...   \n",
       "1  Source B A picture published in a British news...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         answer_text  awarded_marks  \\\n",
       "0  Source A is critical of the \\nBolsheviks as in...              1   \n",
       "1  \\nI think Sources\\nB and C are very useful to ...              4   \n",
       "2  The Schlieffen plan led to problems in 1914 as...              0   \n",
       "3   I agree with this statement as I believe the ...              8   \n",
       "4   I agree with this statement as I believe the ...              3   \n",
       "\n",
       "   total_marks  ...  topic_id  answer_scanned_image    start_time  \\\n",
       "0            4  ...       NaN                   NaN  1.721054e+09   \n",
       "1           12  ...       NaN                   NaN  1.721054e+09   \n",
       "2            8  ...       NaN                   NaN  1.721054e+09   \n",
       "3           16  ...       NaN                   NaN  1.721054e+09   \n",
       "4            4  ...       NaN                   NaN  1.721054e+09   \n",
       "\n",
       "                                   llm_graded_answer  \\\n",
       "0  ### Step-by-Step Grading Explanation\\n\\n#### 1...   \n",
       "1  ### Step-by-Step Grading Explanation\\n\\n#### 1...   \n",
       "2  ### Step-by-Step Grading Explanation\\n\\n#### 1...   \n",
       "3  ### Step-by-Step Grading Explanation\\n\\n#### 1...   \n",
       "4  Based on the provided Mark Scheme, let's asses...   \n",
       "\n",
       "                     llm_graded_answer_token_costing llm_awarded_marks  \\\n",
       "0  {'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...                 2   \n",
       "1  {'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...                 4   \n",
       "2  {'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...                 1   \n",
       "3  {'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...                 7   \n",
       "4  {'burn_in_runs': 2, 'model': 'gpt-4o', 'prompt...                 3   \n",
       "\n",
       "                     llm_awarded_marks_token_costing  llm_mark_hitrate  \\\n",
       "0  {'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...             False   \n",
       "1  {'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...              True   \n",
       "2  {'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...             False   \n",
       "3  {'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...             False   \n",
       "4  {'burn_in_runs': 1, 'model': 'gpt-4o', 'prompt...              True   \n",
       "\n",
       "       end_time  elapsed_time_in_seconds  \n",
       "0  1.721054e+09                39.719050  \n",
       "1  1.721054e+09                27.226788  \n",
       "2  1.721054e+09                22.838951  \n",
       "3  1.721054e+09                36.361025  \n",
       "4  1.721054e+09                20.125219  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_marked_questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute performance statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_marked_questions_reduced = teacher_marked_questions[~teacher_marked_questions.question_type.isin([\"bs_mcq\", \"bs_computation\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean:  0.30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>number_of_questions_count</th>\n",
       "      <th>proportion_of_questions_covered_sum</th>\n",
       "      <th>proportion_of_questions_covered_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hs_explain</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hs_spag</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_type  number_of_questions_count  \\\n",
       "0    hs_analyse                          4   \n",
       "1    hs_explain                          8   \n",
       "2  hs_judgement                          4   \n",
       "3       hs_spag                          4   \n",
       "\n",
       "   proportion_of_questions_covered_sum  proportion_of_questions_covered_mean  \n",
       "0                                    0                                 0.000  \n",
       "1                                    3                                 0.375  \n",
       "2                                    1                                 0.250  \n",
       "3                                    2                                 0.500  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hitrate\n",
    "## Mean overall\n",
    "mean_hitrate = np.mean(teacher_marked_questions_reduced.llm_mark_hitrate)\n",
    "\n",
    "## Mean by question type\n",
    "mean_hitrate_by_question_type = teacher_marked_questions_reduced.groupby(by=[\"question_type\"], as_index = False).agg({\"question_id\": \"count\", \"llm_mark_hitrate\": [\"sum\", \"mean\"]}).rename(columns={\"question_id\": \"number_of_questions\", \"llm_mark_hitrate\": \"proportion_of_questions_covered\"})\n",
    "mean_hitrate_by_question_type.columns = [\"_\".join(col_name).rstrip('_') for col_name in mean_hitrate_by_question_type.columns]\n",
    "\n",
    "print(f\"Overall Mean:  {mean_hitrate:.2f}\")\n",
    "mean_hitrate_by_question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>total_marks</th>\n",
       "      <th>number_of_questions</th>\n",
       "      <th>hitrate_frequency</th>\n",
       "      <th>mean_hitrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>hs_explain</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>hs_explain</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.2</td>\n",
       "      <td>hs_spag</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id question_type  total_marks  number_of_questions  \\\n",
       "0          1.0    hs_explain            4                    4   \n",
       "1          2.0    hs_explain           12                    4   \n",
       "2          3.0    hs_analyse            8                    4   \n",
       "3          4.1  hs_judgement           16                    4   \n",
       "4          4.2       hs_spag            4                    4   \n",
       "\n",
       "   hitrate_frequency  mean_hitrate  \n",
       "0                  1          0.25  \n",
       "1                  2          0.50  \n",
       "2                  0          0.00  \n",
       "3                  1          0.25  \n",
       "4                  2          0.50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hitrate by Question ID\n",
    "teacher_marked_questions_reduced.head()\n",
    "\n",
    "question_hit_rate = teacher_marked_questions_reduced.groupby(by=['question_id', \"question_type\", \"total_marks\"], as_index=False).agg({\"llm_mark_hitrate\": [\"count\", \"sum\", \"mean\"]})\n",
    "question_hit_rate.columns = [\"question_id\", \"question_type\", \"total_marks\", \"number_of_questions\", \"hitrate_frequency\", \"mean_hitrate\"]\n",
    "\n",
    "question_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean:  1.60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>number_of_questions</th>\n",
       "      <th>marks_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>4</td>\n",
       "      <td>2.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hs_explain</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>4</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hs_spag</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_type  number_of_questions  marks_mean_absolute_error\n",
       "0    hs_analyse                    4                      2.750\n",
       "1    hs_explain                    8                      0.875\n",
       "2  hs_judgement                    4                      2.250\n",
       "3       hs_spag                    4                      1.250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "teacher_marked_questions_reduced[\"marks_mean_absolute_error\"] = teacher_marked_questions_reduced.apply(lambda row: ranged_error(x=row['llm_awarded_marks'], range_of_values=[row['awarded_marks']]), axis=1)\n",
    "\n",
    "# Overall\n",
    "marks_mea = np.mean(teacher_marked_questions_reduced.marks_mean_absolute_error)\n",
    "\n",
    "## Mean by question type\n",
    "marks_mea_by_question_type = teacher_marked_questions_reduced.groupby(by=[\"question_type\"], as_index = False).agg({\"question_id\": \"count\", \"marks_mean_absolute_error\": \"mean\"}).rename(columns={\"question_id\": \"number_of_questions\"})\n",
    "\n",
    "print(f\"Overall Mean:  {marks_mea:.2f}\")\n",
    "marks_mea_by_question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>marks_mean_absolute_error</th>\n",
       "      <th>number_of_questions</th>\n",
       "      <th>number_of_questions_by_question_type</th>\n",
       "      <th>questions_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hs_analyse</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hs_explain</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hs_explain</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hs_explain</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hs_judgement</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hs_spag</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hs_spag</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hs_spag</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_type  marks_mean_absolute_error  number_of_questions  \\\n",
       "0     hs_analyse                          1                    1   \n",
       "1     hs_analyse                          2                    2   \n",
       "2     hs_analyse                          6                    1   \n",
       "3     hs_explain                          0                    3   \n",
       "4     hs_explain                          1                    3   \n",
       "5     hs_explain                          2                    2   \n",
       "6   hs_judgement                          0                    1   \n",
       "7   hs_judgement                          1                    1   \n",
       "8   hs_judgement                          3                    1   \n",
       "9   hs_judgement                          5                    1   \n",
       "10       hs_spag                          0                    2   \n",
       "11       hs_spag                          1                    1   \n",
       "12       hs_spag                          4                    1   \n",
       "\n",
       "    number_of_questions_by_question_type  questions_proportion  \n",
       "0                                      4                 0.250  \n",
       "1                                      4                 0.500  \n",
       "2                                      4                 0.250  \n",
       "3                                      8                 0.375  \n",
       "4                                      8                 0.375  \n",
       "5                                      8                 0.250  \n",
       "6                                      4                 0.250  \n",
       "7                                      4                 0.250  \n",
       "8                                      4                 0.250  \n",
       "9                                      4                 0.250  \n",
       "10                                     4                 0.500  \n",
       "11                                     4                 0.250  \n",
       "12                                     4                 0.250  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error by question deviation\n",
    "question_type_mark_deviations = teacher_marked_questions_reduced.groupby(by=[\"question_type\", \"marks_mean_absolute_error\"], as_index = False).agg({\"question_id\": \"count\"})\n",
    "question_type_totals = teacher_marked_questions_reduced.groupby(by=[\"question_type\"], as_index = False).agg({\"question_id\": \"count\"})\n",
    "\n",
    "question_type_mark_deviation_joined = pd.merge(question_type_mark_deviations, question_type_totals, on = \"question_type\", how=\"left\")\n",
    "question_type_mark_deviation_joined['questions_proportion'] = question_type_mark_deviation_joined.apply(lambda x: x['question_id_x']/ x['question_id_y'], axis = 1)\n",
    "\n",
    "question_type_mark_deviation_joined = question_type_mark_deviation_joined.rename(columns={\"question_id_x\": \"number_of_questions\", \"question_id_y\": \"number_of_questions_by_question_type\"})\n",
    "question_type_mark_deviation_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_hitrate</th>\n",
       "      <th>marks_mean_abolute_error</th>\n",
       "      <th>number_of_questions</th>\n",
       "      <th>elapsed_time_in_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_hitrate  marks_mean_abolute_error  number_of_questions  \\\n",
       "0           0.3                       1.6                   20   \n",
       "\n",
       "   elapsed_time_in_minutes  \n",
       "0                10.033333  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_stats = pd.DataFrame({\"mean_hitrate\": [np.round(mean_hitrate, 2)], \"marks_mean_abolute_error\": [np.round(marks_mea, 2)], \"number_of_questions\": [teacher_marked_questions.shape[0]], \"elapsed_time_in_minutes\": [np.round( np.sum(teacher_marked_questions.elapsed_time_in_seconds), 0) / 60]})\n",
    "overall_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation statistics tables\n",
    "savedir = Path(workdir) / \"validation_results\" / \"business_studies\" / year / \"validation_statistics\"\n",
    "\n",
    "Path(savedir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_marked_questions.to_csv(savedir / \"examiner_llm_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_stats.to_csv(savedir / \"mean_hitrate.csv\", index=False)\n",
    "mean_hitrate_by_question_type.to_csv(savedir / \"mean_hitrate_by_question_type.csv\", index=False)\n",
    "marks_mea_by_question_type.to_csv(savedir / \"mea_marks_by_question_type.csv\", index=False)\n",
    "question_type_mark_deviation_joined.to_csv(savedir / \"question_type_marks_deviation.csv\", index=False)\n",
    "question_hit_rate.to_csv(savedir / \"question_hit_rate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assessment_llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
